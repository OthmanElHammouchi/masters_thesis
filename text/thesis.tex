\documentclass[12pt, titlepage]{article}

\usepackage{amsmath, amsfonts, amsthm, amssymb}
\usepackage{tikz, tikz-cd}
\usepackage{mathtools}
\usepackage[nottoc,numbib]{tocbibind}
\usepackage[backend=bibtex]{biblatex} 
\usepackage{derivative}
\usepackage{esint}
\usepackage{xparse}
\usepackage{braket}

\usepackage{enumerate}
\usepackage[mathscr]{euscript}
\usepackage{mathrsfs}
\usepackage{comment}
\usepackage{bm}
\usepackage{caption}

\begin{document}
\section{Pattern break detection}

The chainladder method ranks among the most frequently applied loss reserving techniques in insurance. Originally conceived as a purely computational algorithm, there have since been various attempts to cast it in a proper stochastic framework. No matter which of these models chooses to employ, there is one particular assumption the reserving actuary cannot escape: that the development pattern observed in earlier cohorts is somehow applicable to later ones. This seems very reasonable, of course: if our models are to use the past as a guide to the future, they will be bound to postulate the existence of \emph{some} element of constancy in the underlying data generating process. 

Consider, for example, a cumulative claims process $(C_{ij})_{0 \leq i \leq I, 0 \leq j \leq J}$ (index $i$ denoting the cohort and $j$ the development period) satisfying the model assumptions of Mack's method:
\begin{gather}
\mathbb{E}[C_{ij} \ \Vert \ C_{i, j - 1}, \dots, C_{i1}] = \mathbb{E}[C_{ij} \ \Vert \ C_{i, j - 1}] = f_{j - 1} C_{i, j - 1} \\
\mathrm{Var}[C_{ij} \ \Vert \ C_{i, j - 1}, \dots, C_{i1}] = \mathrm{Var}[C_{ij} \ \Vert \ C_{i, j - 1}] = \sigma_{j - 1}^2 C_{i, j - 1}
\end{gather},
for $i \in \{ 0, \dots, I \}$ and
\begin{equation}
\{ C_{i, 0}, \dots, C_{i, I - i} \}, \{ C_{i', 0}, \dots, C_{i', I - i'} \} \ \text{independent for} \ i \neq i' \,.
\end{equation}
Using the rules of conditional probability, we can rewrite the first equation as
\begin{gather}
\mathbb{E}[\frac{C_{ij}}{C_{i, j - 1}} \ \Vert \ C_{i, j - 1}] = \mathbb{E}[F_{i, j - 1} \ \Vert \ C_{i, j - 1}] = f_{j - 1} %\\
% \mathrm{Var}[\frac{C_{ij}}{C_{i, j - 1}^2} \ \Vert  \ C_{i, j - 1}] = \mathrm{Var}[\frac{F_{i, j - 1}}{C_{i, j - 1}} \ \Vert \ C_{i, j - 1}] = \sigma_{j - 1}^2 \,,
\end{gather}
from which it becomes clear that this is in fact a first-order stationarity assumption over the cohorts on the time series $(F_{i, j - 1})_{0 \leq i \leq I}$. If we further assume that the claims process is conditionally Gaussian, 
\begin{multline}
C_{ij} \ \vert \ C_{i, j - 1} = (f_{j-1}C_{i,j-1} + \sigma_{j-1} \sqrt{C_{i,j-1}} \epsilon_{i, j-1}) \ \vert \ C_{i, j - 1} \\ 
\sim \mathcal{N}(f_{j - 1}C_{i, j - 1}, \sigma_{j - 1}^2 C_{i, j - 1}) \,,
\end{multline}
with $\epsilon_{ij} \sim \mathcal{N}(0, 1)$ i.i.d., then $F_{i, j - 1} \ \vert \ C_{i, j - 1} \sim \mathcal{N}(f_{j - 1}, \sigma_{j - 1}^2/C_{j - 1})$ and we can consider the residuals
\begin{displaymath}
\frac{(F_{i, j - 1} - f_{j - 1})\sqrt{C_{i, j -1}}}{\sigma_{j - 1}} \sim \mathcal{N}(0, 1) \,,
\end{displaymath}
which should be independent for $i$ ranging over $\{0, \dots, I\}$ under the stationarity assumption.

\end{document}

