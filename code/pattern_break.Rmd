---
title: "Pattern break experiments"
author: "Othman El Hammouchi"
---
```{r}
here::i_am("pattern_break.Rmd")
library(tidyverse)
library(MASS)
library(ggplot2)
library(magrittr)
library(ChainLadder)
library(here)

source(here("pattern_break.r"))
```
We start by generating a claims triangle which satisfies the assumptions of Mack's method.

```{r}
nDev <- ncol(UKMotor)
benchmark <- MackChainLadder(UKMotor)
sigma <- benchmark$sigma
devFac <- benchmark$f[-nDev]
initMean <- mean(UKMotor[, 1])
initStd <- sd(UKMotor[, 1])
```

```{r}
initCol <- rnorm(nDev, initMean, initStd)

claimsTriangle <- matrix(ncol = nDev, nrow = nDev)
claimsTriangle[, 1] <- initCol

for (colIdx in 2:nDev) {
    for (rowIdx in 1:(nDev + 1 - colIdx)) {
        prevC <- claimsTriangle[rowIdx, colIdx - 1]
        claimsTriangle[rowIdx, colIdx] <-
            rnorm(1, devFac[colIdx - 1] * prevC, sigma[colIdx - 1] * sqrt(prevC))
    }
}

# kable(claimsTriangle)
```

As expected, the Mack estimator performs very well in this case:

```{r}
res <- MackChainLadder(claimsTriangle)

print(res$f)
```

\section{Perturbing a single observation}

First, we study the effect of perturbing a single observation and propagating this forward. The following function generates such data given a desired outlier column and row and a perturbation factor. We can repeat the simulation for every possible point and a range of perturbations between 0.5 and 1.5. 

```{r}
results <- tibble(
    row = numeric(),
    col = numeric(),
    pert = numeric(),
    triangle = list(),
    reserve = list()
)

for (colIdx in 2:nDev) {
    for (rowIdx in 1:(nDev + 1 - colIdx)) {
        for (pert in seq(0.5, 1.5, length.out = 10)) {
            triangle <- singleOutlier(nDev, initMean, initStd, devFac, sigma, colIdx, rowIdx, pert = pert)
            reserve <- bootReserve(triangle, 1e3) %>% list()
            triangle %<>% list()
            results %<>% add_row(row = rowIdx, col = colIdx, triangle = triangle, pert = pert, reserve = reserve)
        }
    }
}
```

Now let's take a look at the bootstrap mean as a function of the perturbation for different rows and columns.

```{r}
results %<>%
    mutate(mean = map(reserve, mean, na.rm = TRUE)) %>%
    unnest_auto(mean)
```

```{r}
ggplot(data = results) +
    geom_point(aes(pert, mean)) +
    facet_wrap(vars(col))
```

```{r}
ggplot(data = results) +
    geom_point(aes(pert, mean)) +
    facet_wrap(vars(row))
```

Surprisingly, the plots show a higher mean both for smaller and larger perturbations.

\subsection{Gamma distribution}

The problem with using the above normal model is that it allows for negative samples during the bootstrap simulation. To avoid this, we can use a different distribution which still respects Mack's assumptions. If we take for instance $C_{ij} \sim \Gamma(\alpha, \beta)$, then we must choose $\alpha, \beta$ to satisfy

$$
\begin{cases}
\frac{\alpha}{\beta} = f_{j-1} C_{i, j-1} \\
\frac{\alpha}{\beta^2} = \sigma^2_{j-1} C_{i, j-1} \,,
\end{cases}
$$

giving the values

$$
\alpha = \frac{f_{j-1}^2 C_{i, j-1}}{\sigma_{j-1}^2} \\
\beta = \frac{f_{j-1}}{\sigma_{j-1}^2} \,,
$$

for the distribution parameters.

```{r}
results <- tibble(
    row = numeric(),
    col = numeric(),
    pert = numeric(),
    triangle = list(),
    reserve = list()
)

for (colIdx in 2:nDev) {
    for (rowIdx in 1:(nDev + 1 - colIdx)) {
        for (pert in seq(0.5, 1.5, length.out = 10)) {
            triangle <- singleOutlierGamma(nDev, initMean, initStd, devFac, sigma, colIdx, rowIdx, pert = pert)
            reserve <- bootReserveGamma(triangle, 1e3) %>% list()
            triangle %<>% list()
            results %<>% add_row(row = rowIdx, col = colIdx, triangle = triangle, pert = pert, reserve = reserve)
        }
    }
}
```

```{r}
results %<>%
    mutate(mean = map(reserve, mean, na.rm = TRUE)) %>%
    unnest_auto(mean)
```

```{r}
ggplot(data = results) +
    geom_point(aes(pert, mean)) +
    facet_wrap(vars(col))
```

```{r}
ggplot(data = results) +
    geom_point(aes(pert, mean)) +
    facet_wrap(vars(row))
```

