---
title: "Pattern break detection"
author: "Othman El Hammouchi"
output: "pdf_document"
header_includes:
    - \usepackage{amsmath}
---
```{r, echo = FALSE}
suppressPackageStartupMessages({
    library(tidyverse)
    library(MASS)
    library(ggplot2)
    library(magrittr)
    library(ChainLadder)
    library(here)
    library(knitr)
    library(gridExtra)
    library(patchwork)
    library(grid)

    library(iterators)
    library(parallel)
    library(doParallel)
    library(foreach)

    registerDoParallel()

    source(here("pattern_break.r"))
})

suppressMessages({
    here::i_am("pattern_break.Rmd")
    knitr::opts_chunk$set(echo = FALSE)
})
```

\section{Introduction}

Stochastic claims reserving methods in non-life insurance are based on models whose underlying assumptions are difficult to verify using classical statistical inference owing to the limited amount of data that's typically available. A possible way to remedy this, which we will explore in this notebook, is through the use of bootstrap simulation. The idea is to start from a sythetic triangle which is constructed to perfectly satisfy some set of assumptions, and then to gauge the sensitivity of the simulated reserve to deviations from said assumptions. We will do this by applying various violations and studying the effect on the bootstrapped predictive distribution. If a significant effect is observed, this suggests a method for identifying observations in real claims data which do not conform to the given model.

\section{Perturbing a single observation}

Let's start by considering the underlying model of Mack's method, which is one the most popular reserving techniques. It makes the following assumptions:

\begin{gather}
\mathbb{E}[C_{ij} \ \Vert \ C_{i, j - 1}, \dots, C_{i1}] = \mathbb{E}[C_{ij} \ \Vert \ C_{i, j - 1}] = f_{j - 1} C_{i, j - 1} \\
\mathrm{Var}[C_{ij} \ \Vert \ C_{i, j - 1}, \dots, C_{i1}] = \mathrm{Var}[C_{ij} \ \Vert \ C_{i, j - 1}] = \sigma_{j - 1}^2 C_{i, j - 1}
\end{gather},
for $i \in \{ 0, \dots, I \}$ and
\begin{equation}
\{ C_{i, 0}, \dots, C_{i, I - i} \}, \{ C_{i', 0}, \dots, C_{i', I - i'} \} \ \text{independent for} \ i \neq i' \,.
\end{equation}

The first violation we consider is of the mean assumption. We can repeat the simulation for every possible point and a range of perturbations between 0.5 and 1.5. 

triangle conforming to Mack's assumptions. For added realism, we borrow the development factors and $\sigma_j$-parameters from a real dataset, the UKMotor data from the `ChainLadder` package.

```{r}
set.seed(5)

nDev <- ncol(UKMotor)
benchmark <- suppressWarnings(MackChainLadder(UKMotor))
sigma <- benchmark$sigma
devFacs <- benchmark$f[-nDev]
initCol <- unname(UKMotor[, 1])

claimsTriangle <- matrix(ncol = nDev, nrow = nDev)
claimsTriangle[, 1] <- initCol

for (colIdx in 2:nDev) {
    for (rowIdx in 1:(nDev + 1 - colIdx)) {
        prevC <- claimsTriangle[rowIdx, colIdx - 1]
        claimsTriangle[rowIdx, colIdx] <-
            rnorm(1, devFacs[colIdx - 1] * prevC, sigma[colIdx - 1] * sqrt(prevC))
    }
}

kable(claimsTriangle)
```

As expected, the Mack estimator performs very well in this case:

```{r}
res <- MackChainLadder(claimsTriangle)

print(res$f)
```

-- Describe that there are multiple ways of doing the bootstrap, depending on how parameter estimation error is quantified, assumptions on the residuals and choice of distribution for incorporating process error --

-- Describe the first class of experiments: we perturb a single observation by drawing from a normal distribution whose mean is multiplied with a given factor. This corresponds to scaling the mean of the corresponding individual development factor from the link ratio adhered to by the rest of the column by that factor. --

-- Remark: the singleOutlier function draws a new initial column and uses new draws every time it is run. An alternative would be to draw the initial column once and only draw additionally in order to introduce the perturbance; this excludes variability -- 

```{r, cache = TRUE}

results <- foreach(outlierColIdx = 2:(nDev - 1), .combine = "rbind", .errorhandling = "pass") %:%
    foreach(pert = seq(0.5, 1.5, by = 0.25), .combine = "rbind") %dopar% {

        rowResult <- tibble()

        for (outlierRowIdx in 1:(nDev + 1 - outlierColIdx)) {
            triangle <- singleOutlier(outlierColIdx, outlierRowIdx, pert,
                initCol = initCol,
                devFacs = devFacs,
                sigma = sigma)

            reserve <- reserveBoot(triangle, 1e3, distribution = "normal")

            rowResult <- bind_rows(rowResult, tibble(outlierColIdx = outlierColIdx, row = outlierRowIdx, pert = pert, reserve = list(tibble(reserve = reserve))))
        }

        rowResult
    }

stopImplicitCluster()
```

-- Describe what the plots indicate. 

For the columns, there seems to be a lot of variation if the perturbation is applied early, which makes it difficult to distinguish problematic points in earlier columns. Later columns seem to exhibit a clearer influence.

For the rows, the reverse it true: perturbations in earlier rows are more easily distinguished than in later ones. --

```{r}
results <- mutate(results,
    mean = map_dbl(reserve, function(df) mean(df$reserve, na.rm = TRUE)))
```

```{r}
ggplot(data = results) +
    geom_point(aes(pert, mean, colour = row)) +
    facet_wrap(vars(col)) +
    labs(
        x = "Perturbation factor",
        y = "Bootstrap reserve mean"
    ) +
    ggtitle("Reserve estimates for different perturbed columns") +
    theme(plot.title = element_text(hjust = 0.5, size = 25, face = "bold"))
```

```{r}
ggplot(data = results) +
    facet_wrap(vars(row)) +
    geom_point(aes(pert, mean, colour = col)) +
    labs(
        x = "Perturbation factor",
        y = "Bootstrap reserve mean"
    ) +
    ggtitle("Reserve estimates for different perturbed rows") +
    theme(plot.title = element_text(hjust = 0.5, size = 25, face = "bold"))
```

--- We should really do this same kind of analysis for different ways of bootstrapping ---

```{r, cache = TRUE}

methods <- expand_grid(
    residuals_type = c("parametric", "raw", "scaled"),
    bootstrap_type = c("conditional", "unconditional")
    )

results <- foreach(method = iter(methods, by = "row"), .combine = "rbind") %:%
    foreach(colIdx = 2:(nDev - 1), .combine = "rbind", .errorhandling = "pass") %:%
        foreach(pert = seq(0.5, 1.5, by = 0.25), .combine = "rbind") %dopar% {

            rowResult <- tibble()

            for (rowIdx in 1:(nDev + 1 - colIdx)) {
                triangle <- singleOutlier(colIdx, rowIdx, pert,
                    initCol = initCol,
                    devFacs = devFacs,
                    sigma = sigma)

                reserve <- reserveBoot(triangle, 1e3,
                    distribution = "normal",
                    residuals_type = method[[1]],
                    bootstrap_type = method[[2]]
                )

                rowResult <- bind_rows(rowResult, tibble(
                    col = colIdx,
                    row = rowIdx,
                    pert = pert,
                    residuals_type = method[[1]],
                    bootstrap_type = method[[2]],
                    reserve = list(tibble(reserve = reserve))))
            }

            rowResult
        }

stopImplicitCluster()
```

```{r}
plotsByColumn <- results %>%
    mutate(mean = map_dbl(reserve, function(df) mean(df$reserve, na.rm = TRUE))) %>%
    group_by(bootstrap_type, residuals_type) %>%
    group_split() %>%
    map_dfr(function(df) {
        plot <- ggplot(data = df) +
            geom_point(aes(pert, mean, colour = row)) +
            facet_wrap(vars(col)) +
            labs(
                x = "Perturbation factor",
                y = "Bootstrap reserve mean"
            ) +
            ggtitle(
                "Reserve estimates grouped by perturbed column",
                subtitle = paste0("Bootstrap type: ", df$bootstrap_type[1], "\nResiduals type: ", df$residuals_type)
            ) +
            theme(
                plot.title = element_text(size = 25, face = "bold"),
                plot.subtitle = element_text(size = 15)
            )

        return(tibble(
            residuals_type = df$residuals_type[1],
            bootstrap_type = df$bootstrap_type[1],
            plot = list(plot)
        ))
    })

plotsByRow <- results %>%
    mutate(mean = map_dbl(reserve, function(df) mean(df$reserve, na.rm = TRUE))) %>%
    group_by(bootstrap_type, residuals_type) %>%
    group_split() %>%
    map_dfr(function(df) {
        plot <- ggplot(data = df) +
            geom_point(aes(pert, mean, colour = col)) +
            facet_wrap(vars(row)) +
            labs(
                x = "Perturbation factor",
                y = "Bootstrap reserve mean"
            ) +
            ggtitle(
                "Reserve estimates grouped by perturbed row",
                subtitle = paste0("Bootstrap type: ", df$bootstrap_type[1], "\nResiduals type: ", df$residuals_type)
            ) +
            theme(
                plot.title = element_text(size = 25, face = "bold"),
                plot.subtitle = element_text(size = 15)
            )

        return(tibble(
            residuals_type = df$residuals_type[1],
            bootstrap_type = df$bootstrap_type[1],
            plot = list(plot)
        ))
    })


```

--- Now we want to go in the reverse direction: if we start from a perturbed triangle, does removal of the outlying observation create a significant difference in the reserve? ---

```{r, cache = TRUE}

results <- tibble(
    outlierRowIdx = integer(),
    outlierColIdx = integer(),
    exclRowIdx = integer(),
    exclColIdx = integer(),
    reserve = list(),
    mean = numeric())

iterator <- c()

for (outlierColIdx in 2:(nDev - 1)) {
    for (outlierRowIdx in 1:(nDev + 1 - outlierColIdx)) {
        for (pertFac in seq(0.5, 1.5, by = 0.25)) {
        iterator <- rbind(iterator, c(outlierColIdx, outlierRowIdx, pertFac))
        }
    }
}

iterator <- iter(iterator, by = "row")

foreach(triangleConfig = iterator) %:%
            foreach(exclColIdx = 2:(nDev - 1), .combine = "rbind", .errorhandling = "stop") %dopar% {

                    outlierColIdx <- triangleConfig[1]
                    outlierColIdx <- triangleConfig[2]
                    pertFac <- triangleConfig[3]

                    distortedTriangle <- singleOutlier(outlierColIdx, outlierRowIdx, pertFac,
                        initCol = initCol,
                        devFacs = devFacs,
                        sigma = sigma)

                    rowResult <- tibble()
                    for (exclRowIdx in 1:(nDev + 1 - exclColIdx)) {

                        exclude_residuals <- list(c(exclRowIdx, exclColIdx))

                        reserve <- reserveBoot(distortedTriangle, 1e3, exclude_residuals = exclude_residuals)

                        reserveMean <- mean(reserve, na.rm = TRUE)

                        rowResult <- bind_rows(rowResult, tibble(
                            outlierRowIdx = outlierRowIdx,
                            outlierColIdx = outlierColIdx,
                            exclRowIdx = exclRowIdx,
                            exclColIdx = exclColIdx,
                            pertFac = pertFac,
                            reserve = list(reserve),
                            mean = reserveMean))
                    }

                    rowResult
                }

            results <- bind_rows(results, triangleRes)

```

```{r}
col1 <- rnorm(30)
col2 <- rnorm(30)

mat <- cbind(col1, col2)

res <- foreach(row1 = iter(mat, by = "row"), .combine = "rbind") %:%
    foreach(row2 = iter(mat, by = "row"), .combine = "rbind") %dopar% {
        c(row1[1], row2[1])
    }



```

```{r}
if (!file.exists("results/backtest.RDS")) {
    saveRDS(results, "results/backtest.RDS")
}

```

```{r}

plotList <- results %>%
    group_by(outlierRowIdx, outlierColIdx, pertFac) %>%
    mutate(exclMean = mean[(exclRowIdx == outlierRowIdx) & (exclColIdx == outlierColIdx)]) %>%
    ungroup(pertFac) %>% 
    group_map(~ ggplot(.x) +
        geom_violin(aes(x = factor(pertFac), y = mean)) +
            geom_point(aes(factor(pertFac), exclMean), colour = "red") +
            geom_text(aes(label = sprintf("Outlier: (%d, %d)", .y[[1]], .y[[2]]), x = min(pertFac), y = max(mean)), hjust = "left") +
            labs(x = NULL, y = NULL)
    )

p <- marrangeGrob(grobs = plotList,
    ncol = 2,
    nrow = 3,
    top = textGrob("Distribution of bootstrap reserve means for different perturbations", gp = gpar(fontsize = 15)),
    left = textGrob("Perturbation factor", rot = 90),
    bottom = textGrob("Bootstrap means"),
    vp = viewport(width = 0.8, height = 0.8))

ggsave("results/backtest.pdf", p, dpi = "retina", width = 210, height = 297, units = "mm")


```

\subsection{Gamma distribution}

The problem with using the above normal model is that it allows for negative samples during the bootstrap simulation. To avoid this, we can use a different distribution which still respects Mack's assumptions. If we take for instance $C_{ij} \sim \Gamma(\alpha, \beta)$, then we must choose $\alpha, \beta$ to satisfy
\begin{displaymath}
\begin{cases}
\frac{\alpha}{\beta} = f_{j-1} C_{i, j-1} \\
\frac{\alpha}{\beta^2} = \sigma^2_{j-1} C_{i, j-1} \,,
\end{cases}
\end{displaymath}
giving the values
\begin{gather*}
\alpha = \frac{f_{j-1}^2 C_{i, j-1}}{\sigma_{j-1}^2} \\
\beta = \frac{f_{j-1}}{\sigma_{j-1}^2} \,,
\end{gather*}
for the distribution parameters.

```{r, eval = FALSE}

# sequential version of computations in the next chunk; remove 'eval = FALSE' if your setup does not support multithreading

results <- tibble(
    row = numeric(),
    col = numeric(),
    pert = numeric(),
    triangle = list(),
    reserve = list()
)

for (colIdx in 2:nDev) {
    for (rowIdx in 1:(nDev + 1 - colIdx)) {
        for (pert in seq(0.5, 1.5, length.out = 10)) {
            triangle <- singleOutlierGamma(nDev, initMean, initStd, devFacs, sigma, colIdx, rowIdx, pert = pert)
            reserve <- bootReserveGamma(triangle, 1e3) %>% list()
            triangle %<>% list()
            results %<>% add_row(row = rowIdx, col = colIdx, triangle = triangle, pert = pert, reserve = reserve)
        }
    }
}
```
```{r, cache = TRUE}

results <- foreach(colIdx = 2:(nDev - 1), .combine = "rbind", .errorhandling = "pass") %:%
    foreach(pert = seq(0.5, 1.5, by = 0.25), .combine = "rbind") %dopar% {

        rowResult <- tibble()

        for (rowIdx in 1:(nDev + 1 - colIdx)) {
            triangle <- singleOutlier(colIdx, rowIdx, pert,
                nDev = nDev,
                initMean = initMean,
                initStd = initStd,
                devFacs = devFacs,
                sigma = sigma)

            reserve <- reserveBoot(triangle, 1e3, distribution = "normal")

            rowResult <- bind_rows(rowResult, tibble(col = colIdx, row = rowIdx, pert = pert, reserve = list(tibble(reserve = reserve))))
        }

        rowResult
    }

stopImplicitCluster()
```

```{r, eval = FALSE}
results %<>%
    mutate(mean = map(reserve, mean, na.rm = TRUE)) %>%
    unnest_auto(mean)
```

```{r, eval = FALSE}
ggplot(data = results) +
    geom_point(aes(pert, mean)) +
    facet_wrap(vars(col))
```

```{r, eval = FALSE}
ggplot(data = results) +
    geom_point(aes(pert, mean)) +
    facet_wrap(vars(row))
```

